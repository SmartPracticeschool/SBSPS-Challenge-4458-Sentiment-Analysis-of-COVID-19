{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anger_BERT_Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f785096b08c437ebda4cf65aae9deee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0862b8d9f73a4eae98ef22c814d35fee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_25507b8532c742fca73a127eb85270f7",
              "IPY_MODEL_6ef951d2a77e448997051c87796a9b5b"
            ]
          }
        },
        "0862b8d9f73a4eae98ef22c814d35fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25507b8532c742fca73a127eb85270f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_321c1af7e6634e1cbb080eeaf345e49f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29078b1c943d407a9887de64803acdc4"
          }
        },
        "6ef951d2a77e448997051c87796a9b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1787fd2905e449df9659575877f634e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 580kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b31ffb066a94e879c6caeecd3690129"
          }
        },
        "321c1af7e6634e1cbb080eeaf345e49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29078b1c943d407a9887de64803acdc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1787fd2905e449df9659575877f634e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b31ffb066a94e879c6caeecd3690129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1110110437c343cdbf2be53355176bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd03aaacb7ec4f668843d30f35d2fc77",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4701af4a464c4501a4ec7f5c773cb32e",
              "IPY_MODEL_00893e6b582b43719121e53effd4304e"
            ]
          }
        },
        "cd03aaacb7ec4f668843d30f35d2fc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4701af4a464c4501a4ec7f5c773cb32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25aa8a8d196143d8ab4e6ba8b5f02fab",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbcb642e124c456aac2d0c9667162c2a"
          }
        },
        "00893e6b582b43719121e53effd4304e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84066a43ffdf463a992be292f7761c13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.80kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e6e90ef7aae48d7b18d2dda83697705"
          }
        },
        "25aa8a8d196143d8ab4e6ba8b5f02fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbcb642e124c456aac2d0c9667162c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84066a43ffdf463a992be292f7761c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e6e90ef7aae48d7b18d2dda83697705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1926f8e23e8f4d1dae2df1087e11d540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eef7da45a777468a9d68c182280a50d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8ae6716e82d4eae9d920ba94059c9db",
              "IPY_MODEL_4b198c50766e4213802f9ae183eaea6b"
            ]
          }
        },
        "eef7da45a777468a9d68c182280a50d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8ae6716e82d4eae9d920ba94059c9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee37fbe211874666a8746a9a40ed8c1d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3668ad2444247edaa2ad3194ffbeae5"
          }
        },
        "4b198c50766e4213802f9ae183eaea6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7361dae99ea74cc1a4715375ffeb360e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 50.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f27cb6e873f548f2b45f615fb9abdbc0"
          }
        },
        "ee37fbe211874666a8746a9a40ed8c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3668ad2444247edaa2ad3194ffbeae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7361dae99ea74cc1a4715375ffeb360e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f27cb6e873f548f2b45f615fb9abdbc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghagupta11/SBSPS-Challenge-4458-Sentiment-Analysis-of-COVID-19/blob/master/Anger_BERT_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfsXcEb-giFH",
        "colab_type": "text"
      },
      "source": [
        "##Using Colab GPU for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ0U5fAm8SzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d402cb0-dac9-407d-8586-f9d65a6a0e93"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cje2M-P84k1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a64dd3b7-8599-4353-a13a-803b0e9d71b5"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxPa5xZL9QpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "f897535a-c93f-427d-d8de-4903e9087cc5"
      },
      "source": [
        "!pip install transformers\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 27.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 7.2MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 23.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=8f0784d71abecf25376cfb612ddd56138ab9a206ca2fed552ce38a42ceb0f9c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zrbbR-kgxW5",
        "colab_type": "text"
      },
      "source": [
        "##Loading Training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrNJIQy5A6OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjC74fsVNNSb",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "149a59a1-e199-40c8-fea7-bc37d23fda1f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3d2b2d0-1c4f-47d6-8a73-b9d6f1cd9e73\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f3d2b2d0-1c4f-47d6-8a73-b9d6f1cd9e73\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving anger-training-github-small.csv to anger-training-github-small.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmZ6C0uFNeQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "d122a7c2-7ae8-4d01-e5ef-bb05507c8407"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['anger-training-github-small.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.head(10)  \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 1,571\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>pred_anger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Coronavirus has wiped more than 3% off the val...</td>\n",
              "      <td>2020-02-24 23:27:22</td>\n",
              "      <td>Coronavirus has wiped more than 3% off the val...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I gasped cuz at first I read,  \"Do you believe...</td>\n",
              "      <td>2020-02-24 23:07:43</td>\n",
              "      <td>I gasped cuz at first I read,  \"Do you believe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>All Aboard The Blessed Trump Train!\\r\\n\\r\\n#A1...</td>\n",
              "      <td>2020-03-01 23:47:43</td>\n",
              "      <td>All Aboard The Blessed Trump Train!\\r\\n\\r\\n#A1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>SXSW Cancels Film And Music Festival Amid Coro...</td>\n",
              "      <td>2020-03-07 23:39:02</td>\n",
              "      <td>SXSW Cancels Film And Music Festival Amid Coro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Health care workers worry about coronavirus pr...</td>\n",
              "      <td>2020-03-05 23:57:25</td>\n",
              "      <td>Health care workers worry about coronavirus pr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Apple decides not to attend 2020 South by Sout...</td>\n",
              "      <td>2020-03-05 23:50:01</td>\n",
              "      <td>Apple decides not to attend 2020 South by Sout...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Dow Sinks After Federal Reserve Rate Cut To Ea...</td>\n",
              "      <td>2020-03-03 23:54:58</td>\n",
              "      <td>Dow Sinks After Federal Reserve Rate Cut To Ea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>maybe coronavirus will be less picky</td>\n",
              "      <td>2020-02-21 21:56:45</td>\n",
              "      <td>maybe coronavirus will be less picky</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Trump Weekends in Florida as Fear of the Coron...</td>\n",
              "      <td>2020-03-07 23:55:36</td>\n",
              "      <td>Trump Weekends in Florida as Fear of the Coron...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Whoa. Actual medical facts? And presented by a...</td>\n",
              "      <td>2020-02-26 23:56:28</td>\n",
              "      <td>Whoa. Actual medical facts? And presented by a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... pred_anger\n",
              "0           0  ...          0\n",
              "1           1  ...          0\n",
              "2           2  ...          0\n",
              "3           3  ...          0\n",
              "4           4  ...          0\n",
              "5           5  ...          0\n",
              "6           6  ...          0\n",
              "7           7  ...          0\n",
              "8           8  ...          0\n",
              "9           9  ...          1\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E9Kw9PJX4D_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "1834f155-f289-4e6b-f241-9b75ee9466c8"
      },
      "source": [
        "fear = df[['text','pred_anger']]\n",
        "\n",
        "\n",
        "fear.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>pred_anger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coronavirus has wiped more than 3% off the val...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I gasped cuz at first I read,  \"Do you believe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All Aboard The Blessed Trump Train!\\r\\n\\r\\n#A1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SXSW Cancels Film And Music Festival Amid Coro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Health care workers worry about coronavirus pr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Apple decides not to attend 2020 South by Sout...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Dow Sinks After Federal Reserve Rate Cut To Ea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>maybe coronavirus will be less picky</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Trump Weekends in Florida as Fear of the Coron...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Whoa. Actual medical facts? And presented by a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  pred_anger\n",
              "0  Coronavirus has wiped more than 3% off the val...           0\n",
              "1  I gasped cuz at first I read,  \"Do you believe...           0\n",
              "2  All Aboard The Blessed Trump Train!\\r\\n\\r\\n#A1...           0\n",
              "3  SXSW Cancels Film And Music Festival Amid Coro...           0\n",
              "4  Health care workers worry about coronavirus pr...           0\n",
              "5  Apple decides not to attend 2020 South by Sout...           0\n",
              "6  Dow Sinks After Federal Reserve Rate Cut To Ea...           0\n",
              "7               maybe coronavirus will be less picky           0\n",
              "8  Trump Weekends in Florida as Fear of the Coron...           0\n",
              "9  Whoa. Actual medical facts? And presented by a...           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19NJ28_OdboQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = fear.text.values\n",
        "labels = fear.pred_anger.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACqIr4l6g_Ze",
        "colab_type": "text"
      },
      "source": [
        "##Tokenization and Input Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAzWRhNfhJRL",
        "colab_type": "text"
      },
      "source": [
        "##BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SusDz5fPduAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "7f785096b08c437ebda4cf65aae9deee",
            "0862b8d9f73a4eae98ef22c814d35fee",
            "25507b8532c742fca73a127eb85270f7",
            "6ef951d2a77e448997051c87796a9b5b",
            "321c1af7e6634e1cbb080eeaf345e49f",
            "29078b1c943d407a9887de64803acdc4",
            "1787fd2905e449df9659575877f634e7",
            "1b31ffb066a94e879c6caeecd3690129"
          ]
        },
        "outputId": "f99a0e26-a241-40fc-a83d-22252d9a93e3"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f785096b08c437ebda4cf65aae9deee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD7wMGTHeHSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2bda059d-c9e3-4ee3-e708-04a98793acc9"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Coronavirus has wiped more than 3% off the value of global stock markets. As well as the risk to life, there is now a real risk that this has a profoundly damaging effect on the global economy. Brexit may well be the very least of our problems right now.\r\n",
            "https://www.google.com/amp/s/amp.cnn.com/cnn/2020/02/23/business/stock-futures-coronavirus/index.html …\n",
            "Tokenized:  ['corona', '##virus', 'has', 'wiped', 'more', 'than', '3', '%', 'off', 'the', 'value', 'of', 'global', 'stock', 'markets', '.', 'as', 'well', 'as', 'the', 'risk', 'to', 'life', ',', 'there', 'is', 'now', 'a', 'real', 'risk', 'that', 'this', 'has', 'a', 'profoundly', 'damaging', 'effect', 'on', 'the', 'global', 'economy', '.', 'br', '##ex', '##it', 'may', 'well', 'be', 'the', 'very', 'least', 'of', 'our', 'problems', 'right', 'now', '.', 'https', ':', '/', '/', 'www', '.', 'google', '.', 'com', '/', 'amp', '/', 's', '/', 'amp', '.', 'cnn', '.', 'com', '/', 'cnn', '/', '2020', '/', '02', '/', '23', '/', 'business', '/', 'stock', '-', 'futures', '-', 'corona', '##virus', '/', 'index', '.', 'html', '…']\n",
            "Token IDs:  [21887, 23350, 2038, 8342, 2062, 2084, 1017, 1003, 2125, 1996, 3643, 1997, 3795, 4518, 6089, 1012, 2004, 2092, 2004, 1996, 3891, 2000, 2166, 1010, 2045, 2003, 2085, 1037, 2613, 3891, 2008, 2023, 2038, 1037, 28089, 15011, 3466, 2006, 1996, 3795, 4610, 1012, 7987, 10288, 4183, 2089, 2092, 2022, 1996, 2200, 2560, 1997, 2256, 3471, 2157, 2085, 1012, 16770, 1024, 1013, 1013, 7479, 1012, 8224, 1012, 4012, 1013, 23713, 1013, 1055, 1013, 23713, 1012, 13229, 1012, 4012, 1013, 13229, 1013, 12609, 1013, 6185, 1013, 2603, 1013, 2449, 1013, 4518, 1011, 17795, 1011, 21887, 23350, 1013, 5950, 1012, 16129, 1529]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oAB9Jc1gNdT",
        "colab_type": "text"
      },
      "source": [
        "##Sentence to IDs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceMEN0ape4PC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "43720709-c09d-43ea-91a9-625561f18f42"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,  # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                              )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Coronavirus has wiped more than 3% off the value of global stock markets. As well as the risk to life, there is now a real risk that this has a profoundly damaging effect on the global economy. Brexit may well be the very least of our problems right now.\r\n",
            "https://www.google.com/amp/s/amp.cnn.com/cnn/2020/02/23/business/stock-futures-coronavirus/index.html …\n",
            "Token IDs: [101, 21887, 23350, 2038, 8342, 2062, 2084, 1017, 1003, 2125, 1996, 3643, 1997, 3795, 4518, 6089, 1012, 2004, 2092, 2004, 1996, 3891, 2000, 2166, 1010, 2045, 2003, 2085, 1037, 2613, 3891, 2008, 2023, 2038, 1037, 28089, 15011, 3466, 2006, 1996, 3795, 4610, 1012, 7987, 10288, 4183, 2089, 2092, 2022, 1996, 2200, 2560, 1997, 2256, 3471, 2157, 2085, 1012, 16770, 1024, 1013, 1013, 7479, 1012, 8224, 1012, 4012, 1013, 23713, 1013, 1055, 1013, 23713, 1012, 13229, 1012, 4012, 1013, 13229, 1013, 12609, 1013, 6185, 1013, 2603, 1013, 2449, 1013, 4518, 1011, 17795, 1011, 21887, 23350, 1013, 5950, 1012, 16129, 1529, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFN6UL1JhZDN",
        "colab_type": "text"
      },
      "source": [
        "##Padding and Trunking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRAUkC1Wfmr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae4387f1-7826-479a-af99-e33175ab60ad"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufmBrDLrf3d7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "dc144ff2-5151-4338-99a6-39c40803216b"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "MAX_LEN = 280\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 280 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjH9TR5EhfDo",
        "colab_type": "text"
      },
      "source": [
        "##Attension Masks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgZtZaYOhioz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR5YBjc6h0Dk",
        "colab_type": "text"
      },
      "source": [
        "##Train/Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezDLRUVCh3oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                            random_state=1999, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                              random_state=1999, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "817VoxLWiJ1z",
        "colab_type": "text"
      },
      "source": [
        "##Converting to PyTorch DataTypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xdSY0--iOx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQB90Q7fj9GB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTh_UJiakcA_",
        "colab_type": "text"
      },
      "source": [
        "##Modelling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_hW1gKhkaod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1110110437c343cdbf2be53355176bb8",
            "cd03aaacb7ec4f668843d30f35d2fc77",
            "4701af4a464c4501a4ec7f5c773cb32e",
            "00893e6b582b43719121e53effd4304e",
            "25aa8a8d196143d8ab4e6ba8b5f02fab",
            "dbcb642e124c456aac2d0c9667162c2a",
            "84066a43ffdf463a992be292f7761c13",
            "1e6e90ef7aae48d7b18d2dda83697705",
            "1926f8e23e8f4d1dae2df1087e11d540",
            "eef7da45a777468a9d68c182280a50d5",
            "d8ae6716e82d4eae9d920ba94059c9db",
            "4b198c50766e4213802f9ae183eaea6b",
            "ee37fbe211874666a8746a9a40ed8c1d",
            "f3668ad2444247edaa2ad3194ffbeae5",
            "7361dae99ea74cc1a4715375ffeb360e",
            "f27cb6e873f548f2b45f615fb9abdbc0"
          ]
        },
        "outputId": "165f9924-cae3-49e5-bd90-28e1a343800a"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2,    \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "model.cuda()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1110110437c343cdbf2be53355176bb8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1926f8e23e8f4d1dae2df1087e11d540",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rvCp9orlJQx",
        "colab_type": "text"
      },
      "source": [
        "##Set Optimizer and Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JGTLMPVk8DR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate \n",
        "                  eps = 1e-8 # args.adam_epsilon  \n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmwymTLNlaF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                       num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                       num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-WnIyQplkF1",
        "colab_type": "text"
      },
      "source": [
        "##Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT0OWCA5lnDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoDvXiYKmGuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byEN979_mw4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "ad359898-61cc-4f98-9991-ccffb3f73158"
      },
      "source": [
        "import random\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     89.    Elapsed: 0:00:31.\n",
            "  Batch    80  of     89.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:01:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     89.    Elapsed: 0:00:32.\n",
            "  Batch    80  of     89.    Elapsed: 0:01:04.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:01:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     89.    Elapsed: 0:00:32.\n",
            "  Batch    80  of     89.    Elapsed: 0:01:04.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epcoh took: 0:01:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     89.    Elapsed: 0:00:32.\n",
            "  Batch    80  of     89.    Elapsed: 0:01:04.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:01:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wki2VPop3s5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq0pbOZTzUwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "f2fdd112-b395-45e7-c5a7-989c2c86ab67"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pia7E5VU4_rZ",
        "colab_type": "text"
      },
      "source": [
        "##Perform on Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CRqu7F_4-rn",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "53930da2-f11a-4444-d0e2-f7ea2e527717"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c08548a-9c1b-496d-bdb3-fba4f2073f1a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c08548a-9c1b-496d-bdb3-fba4f2073f1a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving anger-testing-github-lite.csv to anger-testing-github-lite.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrvgiGeu5WzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "47439bea-c9b3-4ad0-90a1-fe8d5ca84ee2"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['anger-testing-github-lite.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "anger = df[['clean_text','pred_anger']]\n",
        "anger.sample(10) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 1,546\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>pred_anger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>BBC News - Coronavirus: Germany tightens curbs...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>Health News 5 Ways To Help Your Local Communit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>Please please let us know when the corona viru...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>Lil Nas X and Megan Thee Stallion offer fans f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1094</th>\n",
              "      <td>Engineered #COVID19 theory is troubling in so ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>I’m so sick of hearing about the corona virus ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1525</th>\n",
              "      <td>Can you even imagine the effect of the #Corona...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1506</th>\n",
              "      <td>#coronavirus =&gt; #Italy .\\r\\n\\r\\nPrime Minister...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1204</th>\n",
              "      <td>We stand by Italy during these trying times. S...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1174</th>\n",
              "      <td>Fauci tempers Trump's optimism on chloroquine ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             clean_text  pred_anger\n",
              "1496  BBC News - Coronavirus: Germany tightens curbs...           1\n",
              "543   Health News 5 Ways To Help Your Local Communit...           0\n",
              "1269  Please please let us know when the corona viru...           1\n",
              "528   Lil Nas X and Megan Thee Stallion offer fans f...           0\n",
              "1094  Engineered #COVID19 theory is troubling in so ...           0\n",
              "807   I’m so sick of hearing about the corona virus ...           0\n",
              "1525  Can you even imagine the effect of the #Corona...           0\n",
              "1506  #coronavirus => #Italy .\\r\\n\\r\\nPrime Minister...           0\n",
              "1204  We stand by Italy during these trying times. S...           0\n",
              "1174  Fauci tempers Trump's optimism on chloroquine ...           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1exKwDN8sF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sentence and label lists\n",
        "sentences = anger.clean_text.values\n",
        "labels = anger.pred_anger.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQhtviYw6vxa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0ee4341f-e6c7-4121-fe5b-3977f5e08354"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,546 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-beOzVm9AWP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57b15274-c050-49a9-d890-4d1a0a4659e0"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (anger.pred_anger.sum(), len(anger.pred_anger), (anger.pred_anger.sum() / len(anger.pred_anger) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 358 of 1546 (23.16%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_xkbDSj9MxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c651ff10-7396-45f3-b045-5e5c4a31895f"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZGI4sNF9TlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22de9c2f-f747-4d09-a949-95a4fbce8c43"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0jMJSMzABUc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "31c4fb28-25b2-4eda-ebda-4d637816db2c"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0MmERT_AgL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12KDbnM8A8jV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = model_class.from_pretrained(output_dir)\n",
        "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDiCQyPq90oy",
        "colab_type": "text"
      },
      "source": [
        "##Output Results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kIxJn1Z93eU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7e1e5088-d009-43fb-85dc-59511fbcc9de"
      },
      "source": [
        "frames = [flat_true_labels, flat_predictions]\n",
        "table = pd.DataFrame(frames)\n",
        "results = table.T\n",
        "results.columns =['True', 'Pred'] \n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True</th>\n",
              "      <th>Pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   True  Pred\n",
              "0     0     1\n",
              "1     0     0\n",
              "2     0     0\n",
              "3     0     0\n",
              "4     1     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3CYOh_J-F1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table_to_save = anger.merge(results, left_index=True, right_index=True)\n",
        "table_to_save.to_csv('testing_data_results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnHNl_1ZC8e4",
        "colab_type": "text"
      },
      "source": [
        "##Labelling other data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXfYzRSjGeve",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "df6cde8e-029d-4721-c2eb-bf6bdbda8ce9"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5def5f67-fb77-4653-93b0-10bfc95110bb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5def5f67-fb77-4653-93b0-10bfc95110bb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Dataset_april3.csv to Dataset_april3.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkT2OXz6GelP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "2cdce16b-3313-46ed-d7e4-a3838b555ce4"
      },
      "source": [
        "import io\n",
        "#import pandas as pd\n",
        "df = pd.read_csv(io.BytesIO(uploaded['Dataset_april3.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "print('Number of unlabeled sentences: {:,}\\n'.format(df.shape[0]))\n",
        "anger = df[['created_at','text']]\n",
        "# Display 10 random rows from the data.\n",
        "anger.head(10)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unlabeled sentences: 15,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tue Apr 21 11:31:58 +0000 2020</td>\n",
              "      <td>RT @PARInetwork: 3/ \"When there is no food, pe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tue Apr 21 06:50:59 +0000 2020</td>\n",
              "      <td>Adopt social distancing as a life style till t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tue Apr 21 09:18:34 +0000 2020</td>\n",
              "      <td>RT @ProfAkinAbayomi: ☑️The second death involv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tue Apr 21 13:25:06 +0000 2020</td>\n",
              "      <td>RT @ayinoptions: So the phrase should really g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tue Apr 21 22:16:45 +0000 2020</td>\n",
              "      <td>RT @JoeNBC: MEMO TO PRESIDENT from your CDC Di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Tue Apr 21 21:43:42 +0000 2020</td>\n",
              "      <td>RT @JoeBiden: I know COVID-19 is causing many ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Tue Apr 21 23:26:21 +0000 2020</td>\n",
              "      <td>Why oh why are we beset with evil geniuses fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Wed Apr 22 04:44:14 +0000 2020</td>\n",
              "      <td>RT @MediaActive: Meanwhile, in the South China...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Wed Apr 22 01:12:43 +0000 2020</td>\n",
              "      <td>RT @CMC_MarineCorps: Marines, the PFT requirem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Tue Apr 21 19:44:39 +0000 2020</td>\n",
              "      <td>RT @MelissaJPeltier: So, Dan Patrick is volunt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       created_at                                               text\n",
              "0  Tue Apr 21 11:31:58 +0000 2020  RT @PARInetwork: 3/ \"When there is no food, pe...\n",
              "1  Tue Apr 21 06:50:59 +0000 2020  Adopt social distancing as a life style till t...\n",
              "2  Tue Apr 21 09:18:34 +0000 2020  RT @ProfAkinAbayomi: ☑️The second death involv...\n",
              "3  Tue Apr 21 13:25:06 +0000 2020  RT @ayinoptions: So the phrase should really g...\n",
              "4  Tue Apr 21 22:16:45 +0000 2020  RT @JoeNBC: MEMO TO PRESIDENT from your CDC Di...\n",
              "5  Tue Apr 21 21:43:42 +0000 2020  RT @JoeBiden: I know COVID-19 is causing many ...\n",
              "6  Tue Apr 21 23:26:21 +0000 2020  Why oh why are we beset with evil geniuses fro...\n",
              "7  Wed Apr 22 04:44:14 +0000 2020  RT @MediaActive: Meanwhile, in the South China...\n",
              "8  Wed Apr 22 01:12:43 +0000 2020  RT @CMC_MarineCorps: Marines, the PFT requirem...\n",
              "9  Tue Apr 21 19:44:39 +0000 2020  RT @MelissaJPeltier: So, Dan Patrick is volunt..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2yL9gAquCxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0b2e0ad-35a0-49cf-8408-51ff54475072"
      },
      "source": [
        "sentences = anger.text.values\n",
        "# labels = sadness.sadness.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWbiEM9UDElj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sentence and label lists\n",
        "sentences = anger.text.values\n",
        "# labels = sadness.sadness.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "MAX_LEN = 160\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "# prediction_labels = torch.tensor(labels)\n",
        "# Set the batch size.  \n",
        "batch_size = 16  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_ShnowCDL4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6c971537-b596-4d7e-def1-d4af27d66b55"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions  = []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  # label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  # true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 15,000 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyGHXM-PDVo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgnLNnrcDYZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table1 = pd.DataFrame(flat_predictions)\n",
        "table1.columns = ['anger_output']\n",
        "df1 = df[[ 'created_at', 'text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuHC2-jfDbhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "0818b14b-d929-4385-a44c-ff4dc40d6598"
      },
      "source": [
        "pred_output1 = df1.merge(table1,left_index=True, right_index=True)\n",
        "pred_output1.to_csv('Bert_apr3_anger.csv')\n",
        "pred_output1.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>anger_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14990</th>\n",
              "      <td>Thu Apr 30 18:57:28 +0000 2020</td>\n",
              "      <td>Abolish The Middlemen! #MedicareForAll https:/...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8685</th>\n",
              "      <td>Sun Apr 26 19:50:16 +0000 2020</td>\n",
              "      <td>@Joy997FM  I will suggest to government to mak...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9361</th>\n",
              "      <td>Mon Apr 27 21:04:06 +0000 2020</td>\n",
              "      <td>RT @SarahLudford: “do worst-performing leaders...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10396</th>\n",
              "      <td>Mon Apr 27 18:19:40 +0000 2020</td>\n",
              "      <td>RT @BioTalentCanada: We continue to support em...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6342</th>\n",
              "      <td>Sat Apr 25 10:34:30 +0000 2020</td>\n",
              "      <td>@allisonpearson @Tothemo83592350 Out of curios...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14241</th>\n",
              "      <td>Thu Apr 30 11:39:36 +0000 2020</td>\n",
              "      <td>RT @ndtv: #Watch | \"Number of #coronavirus cas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3816</th>\n",
              "      <td>Thu Apr 23 14:24:29 +0000 2020</td>\n",
              "      <td>RT @theRealKiyosaki: WILL GETTING BACK TO WORK...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5736</th>\n",
              "      <td>Fri Apr 24 09:42:27 +0000 2020</td>\n",
              "      <td>RT @pbhushan1: Must read:What was evident is n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2705</th>\n",
              "      <td>Wed Apr 22 07:45:09 +0000 2020</td>\n",
              "      <td>RT @block_per: With complete or near-complete ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>Tue Apr 21 09:58:40 +0000 2020</td>\n",
              "      <td>RT @JamesHasson20: He got in an altercation wi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           created_at  ... anger_output\n",
              "14990  Thu Apr 30 18:57:28 +0000 2020  ...            1\n",
              "8685   Sun Apr 26 19:50:16 +0000 2020  ...            0\n",
              "9361   Mon Apr 27 21:04:06 +0000 2020  ...            1\n",
              "10396  Mon Apr 27 18:19:40 +0000 2020  ...            0\n",
              "6342   Sat Apr 25 10:34:30 +0000 2020  ...            1\n",
              "14241  Thu Apr 30 11:39:36 +0000 2020  ...            0\n",
              "3816   Thu Apr 23 14:24:29 +0000 2020  ...            0\n",
              "5736   Fri Apr 24 09:42:27 +0000 2020  ...            0\n",
              "2705   Wed Apr 22 07:45:09 +0000 2020  ...            0\n",
              "1156   Tue Apr 21 09:58:40 +0000 2020  ...            1\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEVcjOe6Ddlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e87f8f8-c335-402a-b13f-74abf790d60c"
      },
      "source": [
        "len(pred_output1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    }
  ]
}
